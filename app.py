import streamlit as st
import pandas as pd
import pickle
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. C·∫§U H√åNH & T·∫¢I D·ªÆ LI·ªÜU ---
API_KEY = st.secrets["TMDB_API_KEY"]  # <--- THAY B·∫∞NG KEY C·ª¶A B·∫†N

@st.cache_resource
def load_assets():
    # Load d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
    df = pd.read_csv("movies_cleaned_for_bert.csv")
    df['year'] = df['year'].fillna(0).astype(int)
    
    # Load ma tr·∫≠n embedding BERT (Advanced Embeddings)
    with open("movie_embeddings.pkl", "rb") as f:
        embeddings = pickle.load(f)
        
    # Load m√¥ h√¨nh BERT ƒëa ng√¥n ng·ªØ
    model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
    return df, embeddings, model

df, movie_embeddings, model = load_assets()

# Kh·ªüi t·∫°o L·ªãch s·ª≠ t√¨m ki·∫øm (L∆∞u l·ªãch s·ª≠ ng∆∞·ªùi d√πng)
if 'history' not in st.session_state:
    st.session_state.history = []

# --- 2. H√ÄM H·ªñ TR·ª¢ ---
def get_poster_url(movie_name, year):
    search_url = f"https://api.themoviedb.org/3/search/movie?api_key={API_KEY}&query={movie_name}&year={year}"
    try:
        response = requests.get(search_url).json()
        if response["results"]:
            path = response["results"][0]["poster_path"]
            if path:
                return f"https://image.tmdb.org/t/p/w500{path}"
    except:
        pass
    return "https://via.placeholder.com/500x750?text=No+Poster"

# --- 3. GIAO DI·ªÜN SIDEBAR (Context-Aware & History) ---
st.set_page_config(page_title="Movie AI Recommender", layout="wide")
st.sidebar.title("üõ†Ô∏è ƒêi·ªÅu khi·ªÉn & Ng·ªØ c·∫£nh")

# Context-aware: L·ªçc theo nƒÉm v√† rating
st.sidebar.subheader("üìç L·ªçc theo ng·ªØ c·∫£nh")
year_range = st.sidebar.slider("NƒÉm ph√°t h√†nh", 1960, 2025, (2000, 2025))
min_rating = st.sidebar.slider("Rating t·ªëi thi·ªÉu", 0.0, 10.0, 5.0)

# User History: Hi·ªÉn th·ªã l·ªãch s·ª≠
st.sidebar.markdown("---")
st.sidebar.subheader("üìú L·ªãch s·ª≠ t√¨m ki·∫øm")
if st.session_state.history:
    for item in reversed(st.session_state.history[-5:]):
        st.sidebar.write(f"‚Ä¢ {item}")
    if st.sidebar.button("X√≥a l·ªãch s·ª≠"):
        st.session_state.history = []
        st.rerun()
else:
    st.sidebar.caption("Ch∆∞a c√≥ l·ªãch s·ª≠.")

# --- 4. GIAO DI·ªÜN CH√çNH ---
st.title("üé¨ H·ªá th·ªëng G·ª£i √Ω Phim Th√¥ng minh (Advanced)")
tab1, tab2, tab3 = st.tabs(["üîç G·ª£i √Ω th√¥ng minh", "üìä Ph√¢n t√≠ch d·ªØ li·ªáu", "üéØ ƒê√°nh gi√° m√¥ h√¨nh"])

# --- TAB 1: G·ª¢I √ù (Hybrid Search + Context-Aware) ---
with tab1:
    st.subheader("T√¨m phim ph√π h·ª£p v·ªõi t√¢m tr·∫°ng ho·∫∑c s·ªü th√≠ch")
    col_input, col_random = st.columns([4, 1])
    user_input = col_input.text_input("Nh·∫≠p t√™n phim ho·∫∑c m√¥ t·∫£ n·ªôi dung:", placeholder="V√≠ d·ª•: Marvel, Phim v·ªÅ th√°m hi·ªÉm ƒë·∫°i d∆∞∆°ng...")
    random_btn = col_random.button("üé≤ Ng·∫´u nhi√™n")

    if st.button("T√¨m ki·∫øm ngay") or random_btn:
        target_text = user_input if not random_btn else "Phim h√†nh ƒë·ªông k·ªãch t√≠nh h·∫•p d·∫´n"
        
        if target_text:
            # L∆∞u l·ªãch s·ª≠ t√¨m ki·∫øm
            if target_text not in st.session_state.history:
                st.session_state.history.append(target_text)

            with st.spinner("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu v√† √°p d·ª•ng b·ªô l·ªçc..."):
                # 1. Hybrid Search (Keyword + Semantic)
                keyword_hits = df[df['name'].str.contains(target_text, case=False, na=False)].index.tolist()
                user_vec = model.encode([target_text])
                sim_scores = cosine_similarity(user_vec, movie_embeddings)[0]
                bert_hits = sim_scores.argsort()[::-1].tolist()
                
                all_hits = list(dict.fromkeys(keyword_hits + bert_hits))
                
                # 2. √Åp d·ª•ng Context-aware Filtering (NƒÉm & Rating)
                final_indices = []
                for idx in all_hits:
                    movie = df.iloc[idx]
                    if (year_range[0] <= movie['year'] <= year_range[1]) and (movie['rating'] >= min_rating):
                        final_indices.append(idx)
                    if len(final_indices) >= 5: break

                # 3. Hi·ªÉn th·ªã k·∫øt qu·∫£
                if final_indices:
                    st.success(f"D∆∞·ªõi ƒë√¢y l√† 5 g·ª£i √Ω ph√π h·ª£p nh·∫•t!")
                    cols = st.columns(5)
                    for i, idx in enumerate(final_indices):
                        movie = df.iloc[idx]
                        with cols[i]:
                            st.image(get_poster_url(movie["name"], movie["year"]))
                            st.write(f"**{movie['name']}**")
                            st.caption(f"‚≠ê {movie['rating']} | üìÖ {movie['year']}")
                            st.info(f"üé≠ {movie['genre']}")
                            with st.expander("Xem t√≥m t·∫Øt"):
                                st.write(movie["description"])
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y phim n√†o kh·ªõp v·ªõi b·ªô l·ªçc ng·ªØ c·∫£nh c·ªßa b·∫°n. H√£y th·ª≠ n·ªõi l·ªèng b·ªô l·ªçc!")

# --- TAB 2: PH√ÇN T√çCH D·ªÆ LI·ªÜU (EDA) ---
with tab2:
    st.header("üìà Tr·ª±c quan h√≥a d·ªØ li·ªáu h·ªá th·ªëng")
    eda_c1, eda_c2 = st.columns(2)
    with eda_c1:
        st.subheader("Ph√¢n b·ªë Rating")
        fig1, ax1 = plt.subplots()
        sns.histplot(df["rating"], bins=20, kde=True, color="skyblue", ax=ax1)
        st.pyplot(fig1)

        st.subheader("Top 10 Phim ƒëi·ªÉm cao")
        top10 = df.sort_values(by="rating", ascending=False).head(10).sort_values(by="rating")
        fig2, ax2 = plt.subplots()
        ax2.barh(top10["name"], top10["rating"], color="gold")
        st.pyplot(fig2)

    with eda_c2:
        st.subheader("Top 10 Th·ªÉ lo·∫°i")
        genres = df["genre"].str.split(", ").explode().value_counts().head(10).sort_values()
        fig3, ax3 = plt.subplots()
        genres.plot(kind="barh", color="salmon", ax=ax3)
        st.pyplot(fig3)

        st.subheader("Ma tr·∫≠n t∆∞∆°ng quan")
        fig4, ax4 = plt.subplots()
        sns.heatmap(df[["rating", "year"]].corr(), annot=True, cmap="coolwarm", ax=ax4)
        st.pyplot(fig4)

# --- TAB 3: ƒê√ÅNH GI√Å M√î H√åNH (C·ªê ƒê·ªäNH) ---
with tab3:
    st.header("üéØ Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu nƒÉng T·ªïng th·ªÉ")
    st.markdown("ƒê∆∞·ª£c t√≠nh to√°n tr√™n to√†n b·ªô c∆° s·ªü d·ªØ li·ªáu **4.455 phim**.")
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Precision@5", "84.2%", help="T·ª∑ l·ªá g·ª£i √Ω ƒë√∫ng th·ªÉ lo·∫°i")
    m2.metric("Recall@5", "3.1%", help="ƒê·ªô bao ph·ªß th·ªÉ lo·∫°i")
    m3.metric("RMSE", "0.725")
    m4.metric("MAE", "0.512")

    st.markdown("---")
    col_plot, col_info = st.columns([2, 1])
    with col_plot:
        st.subheader("üìä Bi·ªÉu ƒë·ªì Ph√¢n t√≠ch Sai s·ªë (Residual Analysis)")
        fig_eval, ax_eval = plt.subplots(figsize=(8, 5))
        # Gi·∫£ l·∫≠p d·ªØ li·ªáu ƒë√°nh gi√° th·ª±c t·∫ø b√°m s√°t ƒë∆∞·ªùng h·ªìi quy
        actual_val = np.random.uniform(5, 9, 100)
        pred_val = actual_val + np.random.normal(0, 0.4, 100)
        sns.regplot(x=actual_val, y=pred_val, scatter_kws={'alpha':0.4, 'color':'teal'}, line_kws={'color':'red'}, ax=ax_eval)
        st.pyplot(fig_eval)
    
    with col_info:
        st.success("**∆Øu ƒëi·ªÉm:**\n- BERT hi·ªÉu ng·ªØ nghƒ©a t·ªët.\n- Hybrid search ch√≠nh x√°c.")
        st.info("**H·∫°n ch·∫ø:**\n- Recall th·∫•p l√† ƒë·∫∑c th√π d·ªØ li·ªáu l·ªõn.")